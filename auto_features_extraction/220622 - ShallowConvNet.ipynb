{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as t\n",
    "\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm, trange\n",
    "from torch.optim import Adam\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('eeg_data_csv/')\n",
    "\n",
    "# parameters are acquired during EDA\n",
    "common_electrodes = ['EEG FP1-R', 'EEG FP2-R', 'EEG F3-R', 'EEG F4-R', 'EEG C3-R', 'EEG C4-R', \n",
    "                     'EEG P3-R', 'EEG P4-R', 'EEG O1-R', 'EEG O2-R', 'EEG F7-R', 'EEG F8-R', \n",
    "                     'EEG T3-R', 'EEG T4-R', 'EEG T5-R', 'EEG T6-R', 'EEG FPZ-R', 'EEG FZ-R', \n",
    "                     'EEG CZ-R', 'EEG PZ-R', 'EEG OZ-R']\n",
    "\n",
    "\n",
    "min_length = 21500\n",
    "filter_params = {'l_freq': 1, 'h_freq': 50, 'method': 'iir', 'n_jobs': -1, 'verbose': False}\n",
    "Fs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    X, y = [], []\n",
    "\n",
    "    for csv_file in (data_path/\"Health\").iterdir():\n",
    "        table = pd.read_csv(csv_file)[common_electrodes]\n",
    "        X.append(torch.tensor(table.values.T).float())\n",
    "        y.append(0)\n",
    "\n",
    "    for csv_file in (data_path/\"MDD\").iterdir():\n",
    "        table = pd.read_csv(csv_file)[common_electrodes]\n",
    "        X.append(torch.tensor(table.values.T).float())\n",
    "        y.append(1)\n",
    "\n",
    "    return X, torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data(data_path)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y)\n",
    "\n",
    "train_set = EEGDataset(X_train, y_train, transform=t.RandomCrop((21, 534)))\n",
    "eval_set = EEGDataset(X_val, y_val, transform=t.CenterCrop((21, 534)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_eegs(X, y, size):\n",
    "    n_splits = torch.tensor([(tensor.size(1) - 1) // size for tensor in X])\n",
    "    splits = []\n",
    "    for tensor in X:\n",
    "        splits.extend(tensor.split(size, dim=-1)[:-1])\n",
    "\n",
    "    return torch.stack(splits), y.repeat_interleave(n_splits)\n",
    "\n",
    "X_chunks_train, y_chunks_train = split_eegs(X_train, y_train, 534)\n",
    "X_chunks_val, y_chunks_val = split_eegs(X_val, y_val, 534)\n",
    "\n",
    "train_set = TensorDataset(X_chunks_train, y_chunks_train)\n",
    "eval_set = TensorDataset(X_chunks_val, y_chunks_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=64, num_workers=2, shuffle=True)\n",
    "eval_loader = DataLoader(eval_set, batch_size=64, num_workers=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ShallowConvNet(21, 2).to(device)\n",
    "# model = DeepConvNet(21, 2).to(device)\n",
    "# optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# train_step = 0\n",
    "# eval_step = 0\n",
    "\n",
    "# writer = SummaryWriter(comment=\"\")\n",
    "\n",
    "\n",
    "# def train(model, dataloader):\n",
    "#     global train_step\n",
    "#     model.train()\n",
    "#     for x_batch, y_batch in tqdm(dataloader, leave=False):\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(x_batch.to(device))\n",
    "#         loss = F.cross_entropy(outputs, y_batch.to(device))\n",
    "#         writer.add_scalar(\"train/loss\", loss.item(), train_step)\n",
    "#         train_step += 1\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def validate(model, dataloader):\n",
    "#     global eval_step\n",
    "#     n_correct = 0\n",
    "#     model.eval()\n",
    "#     for x_batch, y_batch in tqdm(dataloader, leave=False):\n",
    "#         outputs = model(x_batch.to(device))\n",
    "#         n_correct += (outputs.argmax(1) == y_batch.to(device)).int().sum().item()\n",
    "#     writer.add_scalar(\"eval/accuracy\", n_correct / len(dataloader.dataset), eval_step)\n",
    "#     eval_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGModel(pl.LightningModule):\n",
    "    def __init__(self, kind=\"deep\", num_channels=21) -> None:\n",
    "        super().__init__()\n",
    "        if kind == \"deep\":\n",
    "            self.model = DeepConvNet(num_channels, 2)\n",
    "        else:\n",
    "            self.model = ShallowConvNet(num_channels, 2)\n",
    "\n",
    "        self.metrics = nn.ModuleDict({\n",
    "            \"accuracy\": torchmetrics.Accuracy(),\n",
    "            \"f1_score\": torchmetrics.F1Score()\n",
    "        })\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.02)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self.model(inputs)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        preds = outputs.argmax(1)\n",
    "        self.log(\"train/loss\", loss)\n",
    "        for name, metric in self.metrics.items():\n",
    "            metric(preds, labels)\n",
    "            self.log(f\"train/{name}\", metric)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self.model(inputs)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        preds = outputs.argmax(1)\n",
    "        self.log(\"eval/loss\", loss, on_step=True, on_epoch=False)\n",
    "        for name in self.metrics:\n",
    "            self.metrics[name].update(preds, labels)\n",
    "            self.log(f\"eval/{name}\", self.metrics[name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name    | Type        | Params\n",
      "----------------------------------------\n",
      "0 | model   | DeepConvNet | 277 K \n",
      "1 | metrics | ModuleDict  | 0     \n",
      "----------------------------------------\n",
      "277 K     Trainable params\n",
      "0         Non-trainable params\n",
      "277 K     Total params\n",
      "1.108     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "495bbd55c59b465b93b70de36463820e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3369abdc24374ccb994dc46c975886a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=100, log_every_n_steps=5)\n",
    "model = EEGModel()\n",
    "\n",
    "trainer.fit(model, train_loader, eval_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca7c7e5e3bc0b818eae448146ffa5b26e6519a92654da819a7cfad5b8d321db8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
